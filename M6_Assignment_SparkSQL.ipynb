{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M6 - Assignment-SparkSQL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jberardini2/Baseball-Stats/blob/main/M6_Assignment_SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 6 Summary and Questions"
      ],
      "metadata": {
        "id": "3EY3XWHuHziK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I work for a technology reseller and the leadership team has asked to report back on sales data for the different companies my company promotes products for. The leadership team is interested in reviewing:\n",
        "\n",
        "The average sales per company\n",
        "\n",
        "The count of sales per company\n",
        "\n",
        "The maximum sales amount per company\n",
        "\n",
        "The minimum sales amount per company\n",
        "\n",
        "The cumulative sales per company\n",
        "\n",
        "The maximum sales amount across companies\n",
        "\n",
        "The distinct count of sales across companies\n",
        "\n",
        "The standard deviation of the sales across companies\n",
        "\n",
        "An ordering of the sales amounts from the maximum amount to the minimum amount"
      ],
      "metadata": {
        "id": "_ZWAn4cA-xh-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11m984jvRxBU"
      },
      "source": [
        "# Setting up PySpark and creating a Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfkKZ_CYZNps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f8dfb6-f92d-4523-b598-e32b1e07823f"
      },
      "source": [
        "# Update environment (if needed)\n",
        "# !sudo apt update\n",
        "\n",
        "# Download and install Java\n",
        "!sudo apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Apache Spark 3.2.1 with Hadoop 3.2\n",
        "!wget -nc -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "1mkG-EApNhqZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the folder\n",
        "!tar xf  spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "XwSRF1Y_N0hS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install findspark library that will locate Spark on the system\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "f8PDYmzROD3M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9Jqb-eZWFy"
      },
      "source": [
        "# Setting the environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIHcyIJ6ZulY"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSNMU92MZzy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01597057-d91a-426a-8aba-f18c460e420d"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iVKYS-iaBjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77ff150-9b03-43b1-fcaf-5cdd70feeddd"
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/My Drive\".\n",
        "!ls \"/content/drive/My Drive/Education/Big Data\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " acite75_99.zip\n",
            " airline.csv\n",
            " books.csv\n",
            "'M1-First-Class (1).mp4'\n",
            " M1-First-Class.mp4\n",
            "'M2 Discussion - Hadoop.gdoc'\n",
            "'M2-Hadoop-Lecture (1).mp4'\n",
            " M2-Hadoop-Lecture.mp4\n",
            "'M2 - Introduction to Hadoop.gdoc'\n",
            "'M3 - Advanced MR Concepts and Hadoop 2.0.gdoc'\n",
            "'M3 Assignment - YARN.gdoc'\n",
            "'M3-Map Reduce and Joins (1).mp4'\n",
            "'M3-Map Reduce and Joins.mp4'\n",
            "'M4 Assignment - HIVE with Google Cloud.gdoc'\n",
            "'M4 - Class Notes for Hive.gdoc'\n",
            "'M4-Google Cloud - uploading to google storage and then copying file using the gsutil command to your VM.JPG'\n",
            "'M4-HADOOP- Example of loading data from local file system into Hadoop.JPG'\n",
            "'M4-HADOOP- Querying for database and table directories.JPG'\n",
            "'M4-HADOOP-Using put to copy from local linux to HDFS location under user directory.JPG'\n",
            "'M4-HIVE-Couting rows.JPG'\n",
            "'M4-HIVE-Creating a Database.JPG'\n",
            "'M4-HIVE-creating defined but empty table.JPG'\n",
            "'M4-HIVE-describe formatted to view text file versus RC file.JPG'\n",
            "'M4-HIVE-Example of joining 2 tables with count-group-orderby.JPG'\n",
            "'M4-HIVE-Example of SQL with count-group-orderby.JPG'\n",
            "'M4-Hive Join Example from my database .gdoc'\n",
            "'M4 - Hive Lecture.mp4'\n",
            "'M4-HIVE-Loading data an RC FIle.JPG'\n",
            "'M4-HIVE-Loading data as an external table from Linux file system.JPG'\n",
            "'M4-HIVE-Loading text file from HDFS text file into the empty table I created.JPG'\n",
            "'M4-HIVE- Sample of Creating Empty Table.JPG'\n",
            "'M4-HIVE-Selecting and viewing the first 5 records.JPG'\n",
            "'M4-HIVE-simple describe and detailed formatted describe.JPG'\n",
            " M4-HIVE-Starting-HIVE.JPG\n",
            "'M4 - Interacting with the Hadoop Ecosystem.gdoc'\n",
            "'M5-Discussion - Spark.gdoc'\n",
            "'M5 - Introduction to Apache Spark.gdoc'\n",
            "'M6 Assignment - PySpark Queries with Colab.gdoc'\n",
            "'M6 - Discussion Question.gdoc'\n",
            "'Overview of Big Data Analytics.gdoc'\n",
            "'Sales Info.csv'\n",
            "'UCI GCP Dataproc Hadoop.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHAE16p2aNqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "90d123b9-70a6-4dd2-af7b-360488523d73"
      },
      "source": [
        "# Import SparkSession from pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create spark session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "spark.version"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss-D4YjJaiLa"
      },
      "source": [
        "df = spark.read.option(\"header\", \"true\").csv(\"/content/drive/My Drive/Education/Big Data/Sales Info.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLwA8Y-GalaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed80f81e-6a94-4178-a24c-fd81806fb99b"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----+\n",
            "|Company|   Person|Sales|\n",
            "+-------+---------+-----+\n",
            "|   ADBE|     Nick|  400|\n",
            "|   ADBE|  Charles|  240|\n",
            "|   ADBE|    Frank|  680|\n",
            "|   SFDC|     Jody| 1200|\n",
            "|   SFDC|      Lee|  248|\n",
            "|   SFDC|  Hui-Ann|  286|\n",
            "|   AMZN|     Dale| 1720|\n",
            "|   AMZN|Christine|  700|\n",
            "|    SAP|     Jill|  500|\n",
            "|    SAP|      Tim|  260|\n",
            "|    SAP|    Danny| 1500|\n",
            "|    SAP|    Peter|  700|\n",
            "|   ORCL|    Brian|  450|\n",
            "|   ORCL|  Randolp|  290|\n",
            "|   ORCL|   Florin|  720|\n",
            "|   ORCL|    James| 1250|\n",
            "|   ORCL|     Eric| 1400|\n",
            "|   BABA|   Darren|  350|\n",
            "|   BABA|   Derick|  475|\n",
            "|   BABA|   Damien|  585|\n",
            "+-------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYDqEORcrWeD",
        "outputId": "d4bbadbd-6ce1-443e-a9a2-4b6e48e04755"
      },
      "source": [
        "#Display the data types of the columns\n",
        "\n",
        "df.dtypes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Company', 'string'), ('Person', 'string'), ('Sales', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbzMv5O4ax7V"
      },
      "source": [
        "Register the DataFrame as a SQL temporary view so that you can interact with it using SQL commands\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLkw3KCva_9W"
      },
      "source": [
        "df.createOrReplaceTempView(\"sales\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYz7APKsbaIg"
      },
      "source": [
        "Query the temporary view using SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25lD-IVrb5AU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c831d2f-5026-46ed-fb0c-5c58e1e139c3"
      },
      "source": [
        "sqlDF = spark.sql(\"SELECT * FROM sales\")\n",
        "sqlDF.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----+\n",
            "|Company|   Person|Sales|\n",
            "+-------+---------+-----+\n",
            "|   ADBE|     Nick|  400|\n",
            "|   ADBE|  Charles|  240|\n",
            "|   ADBE|    Frank|  680|\n",
            "|   SFDC|     Jody| 1200|\n",
            "|   SFDC|      Lee|  248|\n",
            "|   SFDC|  Hui-Ann|  286|\n",
            "|   AMZN|     Dale| 1720|\n",
            "|   AMZN|Christine|  700|\n",
            "|    SAP|     Jill|  500|\n",
            "|    SAP|      Tim|  260|\n",
            "|    SAP|    Danny| 1500|\n",
            "|    SAP|    Peter|  700|\n",
            "|   ORCL|    Brian|  450|\n",
            "|   ORCL|  Randolp|  290|\n",
            "|   ORCL|   Florin|  720|\n",
            "|   ORCL|    James| 1250|\n",
            "|   ORCL|     Eric| 1400|\n",
            "|   BABA|   Darren|  350|\n",
            "|   BABA|   Derick|  475|\n",
            "|   BABA|   Damien|  585|\n",
            "+-------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iczafy1_v8Oc"
      },
      "source": [
        "# Using SQL to interface with Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The average sales per company\n"
      ],
      "metadata": {
        "id": "w3C3WCbMJDpa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059fd9bf-ede2-4127-91ee-c97e0ef977ec",
        "id": "t4JGV8UrOJPm"
      },
      "source": [
        "#Convert the Sales column to a numeric value and name it Average Sales. \n",
        "sqlDF = sqlDF.withColumn(\"Average Sales\", sqlDF.Sales.cast('Integer'))\n",
        "#Group by Company and calculate average sales.\n",
        "sqlDF.groupBy(\"Company\").avg(\"Average Sales\").show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|Company|avg(Average Sales)|\n",
            "+-------+------------------+\n",
            "|   SFDC|             578.0|\n",
            "|   ORCL|             822.0|\n",
            "|    SAP|             740.0|\n",
            "|   AMZN|            1210.0|\n",
            "|   ADBE|             440.0|\n",
            "|   BABA|             600.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The count of sales per company\n"
      ],
      "metadata": {
        "id": "D7lqNcnfJEM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by Company and count how many sales.\n",
        "sqlDF.groupBy(\"Company\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNxLXXK3QEeH",
        "outputId": "bae4556d-1ba5-47c7-a209-2ca051bfe3a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Company|count|\n",
            "+-------+-----+\n",
            "|   SFDC|    3|\n",
            "|   ORCL|    5|\n",
            "|    SAP|    4|\n",
            "|   AMZN|    2|\n",
            "|   ADBE|    3|\n",
            "|   BABA|    4|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The maximum sales amount per company\n"
      ],
      "metadata": {
        "id": "HEgrgAXhJElT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the Sales column to a numeric value and name it I_Sales. \n",
        "sqlDF = sqlDF.withColumn(\"I_Sales\", sqlDF.Sales.cast('Integer'))\n",
        "#Group by Company and calculate max sales per company.\n",
        "sqlDF.groupBy(\"Company\").max(\"I_Sales\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmAEOaqVYWrg",
        "outputId": "08a5077c-1ffd-4423-abb7-1a8f4c6ec441"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+\n",
            "|Company|max(I_Sales)|\n",
            "+-------+------------+\n",
            "|   SFDC|        1200|\n",
            "|   ORCL|        1400|\n",
            "|    SAP|        1500|\n",
            "|   AMZN|        1720|\n",
            "|   ADBE|         680|\n",
            "|   BABA|         990|\n",
            "+-------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VvcgcdZOnGUP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The minimum sales amount per company"
      ],
      "metadata": {
        "id": "qMXEbOYXJFRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the Sales column to a numeric value and name it I_Sales. \n",
        "sqlDF = sqlDF.withColumn(\"I_Sales\", sqlDF.Sales.cast('Integer'))\n",
        "#Group by Company and calculate min sales per company.\n",
        "sqlDF.groupBy(\"Company\").min(\"I_Sales\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I8KbiE7ZAvc",
        "outputId": "aaedbe85-bc5a-4f6d-e49c-1ceebe93a596"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+\n",
            "|Company|min(I_Sales)|\n",
            "+-------+------------+\n",
            "|   SFDC|         248|\n",
            "|   ORCL|         290|\n",
            "|    SAP|         260|\n",
            "|   AMZN|         700|\n",
            "|   ADBE|         240|\n",
            "|   BABA|         350|\n",
            "+-------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The cumulative sales per company"
      ],
      "metadata": {
        "id": "AGGx9PooJFod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the Sales column to a numeric value and name it Count of Sales. \n",
        "sqlDF = sqlDF.withColumn(\"Count of Sales\", sqlDF.Sales.cast('Integer'))\n",
        "#Group by Company and sum sales per company.\n",
        "sqlDF.groupBy(\"Company\").sum(\"Count of Sales\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-11d-RVRGov",
        "outputId": "64ef4233-75a1-446b-e3ee-078624cf4c57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+\n",
            "|Company|sum(Count of Sales)|\n",
            "+-------+-------------------+\n",
            "|   SFDC|               1734|\n",
            "|   ORCL|               4110|\n",
            "|    SAP|               2960|\n",
            "|   AMZN|               2420|\n",
            "|   ADBE|               1320|\n",
            "|   BABA|               2400|\n",
            "+-------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " sqlDF = sqlDF.withColumn('Sales', sqlDF['Sales'].cast('Integer'))\n",
        " sqlDF.groupBy().sum('Sales').show()\n",
        "\n",
        " df2 = df.withColumn('Sales', df['Sales'].cast('float'))\n",
        " df2.groupBy().sum('Sales').show()\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFLqVOsJb9hm",
        "outputId": "f9d53067-1729-465d-fa21-0f7c22a5145a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|sum(Sales)|\n",
            "+----------+\n",
            "|     14944|\n",
            "+----------+\n",
            "\n",
            "+----------+\n",
            "|sum(Sales)|\n",
            "+----------+\n",
            "|   14944.0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The maximum sales amount across companies\n"
      ],
      "metadata": {
        "id": "syucfgV7JGM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The highest sales amount for all companies is 1720 by AMZN.\n",
        "sqlDF = sqlDF.withColumn(\"I_Sales\", sqlDF.Sales.cast('Integer'))\n",
        "sqlDF.groupBy().max(\"I_Sales\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQiA6rTwbfKn",
        "outputId": "ab8bf1de-b0c9-40ce-d642-118c8bfd8797"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|max(I_Sales)|\n",
            "+------------+\n",
            "|        1720|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The distinct count of sales across companies\n"
      ],
      "metadata": {
        "id": "4NuoRpXIJ9D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Company and then do a count followed by distinct.\n",
        "sqlDF.groupBy(\"Company\").count().distinct().show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6399544b-4898-4f76-f7bc-db1b2eab9b73",
        "id": "asZI553KIBbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Company|count|\n",
            "+-------+-----+\n",
            "|   SFDC|    3|\n",
            "|   ORCL|    5|\n",
            "|    SAP|    4|\n",
            "|   AMZN|    2|\n",
            "|   ADBE|    3|\n",
            "|   BABA|    4|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The standard deviation of the sales across companies\n"
      ],
      "metadata": {
        "id": "aMZzSAkLJ9gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pyspark.sql.functions as F\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "sqlDF = sqlDF.withColumn(\"I_Sales\", sqlDF.Sales.cast('Integer'))\n",
        "# Standard deviation of sales by company\n",
        "sqlDF.groupBy(\"Company\").agg(F.stddev(\"I_Sales\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuRfn9q0OAvY",
        "outputId": "87b44788-4385-46eb-ed40-8b7f731d71b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|Company|stddev_samp(I_Sales)|\n",
            "+-------+--------------------+\n",
            "|   SFDC|   539.0027829241701|\n",
            "|   ORCL|    487.103685060994|\n",
            "|    SAP|   537.6492040974921|\n",
            "|   AMZN|   721.2489168102785|\n",
            "|   ADBE|  222.71057451320087|\n",
            "|   BABA|    277.158197906298|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An ordering of the sales amounts from the maximum amount to the minimum amount"
      ],
      "metadata": {
        "id": "ogiwTl0lJ92P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To sort descending its necessary to use the \"col\" function. According to documentation orderBy gives ascending only.\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "#sqlDF = sqlDF.withColumn(\"I_Sales\", sqlDF.Sales.cast('Integer'))\n",
        "\n",
        "sqlDF = sqlDF.drop(\"Average Sales\",\"Count of Sales\",\"Sales\")\n",
        "\n",
        "print (\"2 diferent ways to sort\")\n",
        "sqlDF = sqlDF.orderBy('I_Sales', ascending=False)\n",
        "sqlDF.show()\n",
        "sqlDF = sqlDF.orderBy(col(\"I_Sales\").desc())\n",
        "sqlDF.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WASXDpNhO_4Q",
        "outputId": "6ebeab37-4e50-472a-95f6-f9694d508e1e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 diferent ways to sort\n",
            "+-------+---------+-------+\n",
            "|Company|   Person|I_Sales|\n",
            "+-------+---------+-------+\n",
            "|   AMZN|     Dale|   1720|\n",
            "|    SAP|    Danny|   1500|\n",
            "|   ORCL|     Eric|   1400|\n",
            "|   ORCL|    James|   1250|\n",
            "|   SFDC|     Jody|   1200|\n",
            "|   BABA|    David|    990|\n",
            "|   ORCL|   Florin|    720|\n",
            "|    SAP|    Peter|    700|\n",
            "|   AMZN|Christine|    700|\n",
            "|   ADBE|    Frank|    680|\n",
            "|   BABA|   Damien|    585|\n",
            "|    SAP|     Jill|    500|\n",
            "|   BABA|   Derick|    475|\n",
            "|   ORCL|    Brian|    450|\n",
            "|   ADBE|     Nick|    400|\n",
            "|   BABA|   Darren|    350|\n",
            "|   ORCL|  Randolp|    290|\n",
            "|   SFDC|  Hui-Ann|    286|\n",
            "|    SAP|      Tim|    260|\n",
            "|   SFDC|      Lee|    248|\n",
            "+-------+---------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+---------+-------+\n",
            "|Company|   Person|I_Sales|\n",
            "+-------+---------+-------+\n",
            "|   AMZN|     Dale|   1720|\n",
            "|    SAP|    Danny|   1500|\n",
            "|   ORCL|     Eric|   1400|\n",
            "|   ORCL|    James|   1250|\n",
            "|   SFDC|     Jody|   1200|\n",
            "|   BABA|    David|    990|\n",
            "|   ORCL|   Florin|    720|\n",
            "|    SAP|    Peter|    700|\n",
            "|   AMZN|Christine|    700|\n",
            "|   ADBE|    Frank|    680|\n",
            "|   BABA|   Damien|    585|\n",
            "|    SAP|     Jill|    500|\n",
            "|   BABA|   Derick|    475|\n",
            "|   ORCL|    Brian|    450|\n",
            "|   ADBE|     Nick|    400|\n",
            "|   BABA|   Darren|    350|\n",
            "|   ORCL|  Randolp|    290|\n",
            "|   SFDC|  Hui-Ann|    286|\n",
            "|    SAP|      Tim|    260|\n",
            "|   SFDC|      Lee|    248|\n",
            "+-------+---------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Zrczk0Rc-sa5",
        "outputId": "257b2716-4dcc-4cfd-c2b9-79be0011f1dc"
      },
      "source": [
        "# Print the date and time of when homework was worked on.\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fri, 03 June 2022 12:44:24'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}